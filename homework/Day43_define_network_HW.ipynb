{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Day43_define_network_HW.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6JTrp9sX5b3e","colab_type":"text"},"source":["### 作業\n","請嘗試使用 keras 來定義一個直接預測 15 個人臉關鍵點坐標的檢測網路，以及適合這個網路的 loss function\n","\n","\n","Hint: 參考前面的電腦視覺深度學習基礎"]},{"cell_type":"markdown","metadata":{"id":"eaa5hq9_5b3i","colab_type":"text"},"source":["### 範例\n","接下來的程式碼會示範如何定義一個簡單的 CNN model"]},{"cell_type":"code","metadata":{"id":"qi5itR_D5b3j","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-PYfNMg5b3o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"f116184f-e88d-479f-9168-173fff5d5aa6","executionInfo":{"status":"ok","timestamp":1580950970901,"user_tz":-480,"elapsed":25650,"user":{"displayName":"Jian-Jhih Lai","photoUrl":"","userId":"06705720842516758594"}}},"source":["# 使用 colab 環境的同學請執行以下程式碼\n","%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import os\n","from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","%cd 'gdrive/My Drive/1st-DL-CVMarathon/Day043'\n","# os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n","# %cd cupoy_cv_part4 # 可以自己改路徑"],"execution_count":4,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","1.15.0\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","[Errno 2] No such file or directory: 'gdrive/My Drive/GEODAC/1st-DL-Marathon/Day043'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KbLmVh69GuEf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"73a128c5-2439-4a98-ff87-0b4c9875d50a","executionInfo":{"status":"ok","timestamp":1580952413151,"user_tz":-480,"elapsed":13753,"user":{"displayName":"Jian-Jhih Lai","photoUrl":"","userId":"06705720842516758594"}}},"source":["# 如果要使用 kaggle API 下載資料的話，請用以下程式碼\n","os.environ['KAGGLE_USERNAME'] = 'jianjhihlai' # 請按照 Day42 簡報內容，獲取 kaggle api 需要用到的 username\n","os.environ['KAGGLE_KEY'] = '______' # 請按照 Day42 簡報獲取 kaggle api 需要用到的 key\n","!kaggle competitions download -c facial-keypoints-detection\n","!unzip test.zip\n","!unzip training.zip"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","Downloading SampleSubmission.csv to /content/gdrive/My Drive/GEODAC/1st-DL-CVMarathon/Day043\n","  0% 0.00/201k [00:00<?, ?B/s]\n","100% 201k/201k [00:00<00:00, 25.7MB/s]\n","Downloading test.zip to /content/gdrive/My Drive/GEODAC/1st-DL-CVMarathon/Day043\n"," 31% 5.00M/16.0M [00:00<00:00, 19.2MB/s]\n","100% 16.0M/16.0M [00:00<00:00, 45.8MB/s]\n","Downloading training.zip to /content/gdrive/My Drive/GEODAC/1st-DL-CVMarathon/Day043\n"," 82% 49.0M/60.1M [00:00<00:00, 36.9MB/s]\n","100% 60.1M/60.1M [00:00<00:00, 75.9MB/s]\n","Downloading IdLookupTable.csv to /content/gdrive/My Drive/GEODAC/1st-DL-CVMarathon/Day043\n","  0% 0.00/843k [00:00<?, ?B/s]\n","100% 843k/843k [00:00<00:00, 119MB/s]\n","Archive:  test.zip\n","  inflating: test.csv                \n","Archive:  training.zip\n","  inflating: training.csv            \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UfD9a1VL5b3r","colab_type":"code","colab":{}},"source":["# 讀取資料集以及做前處理的函數\n","def load_data(dirname):\n","    # 讀取 csv 文件\n","    data = pd.read_csv(dirname)\n","    # 過濾有缺失值的 row\n","    data = data.dropna()\n","\n","    # 將圖片像素值讀取為 numpy array 的形態\n","    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n","\n","    # 單獨把圖像 array 抽取出來\n","    imgs = np.vstack(data['Image'].values)/255\n","    # reshape 為 96 x 96\n","    imgs = imgs.reshape(data.shape[0], 96, 96)\n","    # 轉換為 float\n","    imgs = imgs.astype(np.float32)\n","    \n","    # 提取坐標的部分\n","    points = data[data.columns[:-1]].values\n","\n","    # 轉換為 float\n","    points = points.astype(np.float32)\n","\n","    # normalize 坐標值到 [-0.5, 0.5]\n","    points = points/96 - 0.5\n","    \n","    return imgs, points"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P77Sjs7t5b3v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"79dec3a6-d7c7-4267-8b04-a542e4aba252","executionInfo":{"status":"ok","timestamp":1580952449669,"user_tz":-480,"elapsed":5632,"user":{"displayName":"Jian-Jhih Lai","photoUrl":"","userId":"06705720842516758594"}}},"source":["# 讀取資料\n","imgs_train, points_train = load_data(dirname = 'training.csv')\n","print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["圖像資料: (2140, 96, 96) \n","關鍵點資料: (2140, 30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"giocQgcF5b30","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Concatenate, Lambda\n","from keras import backend as K\n","from keras import regularizers\n","from keras import initializers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GR1_qJeR5q99","colab_type":"code","colab":{}},"source":["def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n","    if name is not None:\n","        conv_name = name + '_conv'\n","        bn_name = name + '_bn'\n","        act_name = name + '_act'\n","    else:\n","        conv_name = None\n","        bn_name = None\n","        act_name = None\n","    if K.image_data_format() == 'channels_first':\n","        bn_axis = 1\n","    else:\n","        bn_axis = 3\n","    x = Conv2D(\n","            filters, kernel_size,\n","            strides=strides, padding=padding,\n","            use_bias=False, name=conv_name,\n","            kernel_regularizer=regularizers.l2(0.00004),\n","            kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n","    if normalizer:\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","    if activation:\n","        x = Activation(activation, name=act_name)(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2LNdbUW5saZ","colab_type":"code","colab":{}},"source":["def inception_resnet_block(x, scale, block_type, activation='relu'):\n","    '''scale: scaling factor to scale the residuals (i.e., the output of\n","            passing `x` through an inception module) before adding them\n","            to the shortcut branch. Let `r` be the output from the residual branch,\n","            the output of this block will be `x + scale * r`.(簡單來說就是控制Residual branch的比例)'''\n","    if block_type == 'Incpetion_Block-A':\n","        branch_0 = Conv2d_bn(x, 32, (1, 1), name='inceptiona_bn_0')\n","        branch_1 = Conv2d_bn(x, 32, (1, 1), name='inceptiona_bn_1a')\n","        branch_1 = Conv2d_bn(branch_1, 32, (3, 3), name='Inceptiona_bn_1b')\n","        branch_2 = Conv2d_bn(x, 32, (1, 1), name='inceptiona_bn_2a')\n","        branch_2 = Conv2d_bn(branch_2, 48, (3, 3), name='inceptiona_bn_2b')\n","        branch_2 = Conv2d_bn(branch_2, 64, (3, 3), name='inceptiona_bn_2c')\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'Incpetion_Block-B':\n","        branch_0 = Conv2d_bn(x, 192, (1, 1), name='inceptionb_bn_0')\n","        branch_1 = Conv2d_bn(x, 128, (1, 1), name='inceptionb_bn_1a')\n","        branch_1 = Conv2d_bn(branch_1, 160, (1, 7), name='inceptionb_bn_1b')\n","        branch_1 = Conv2d_bn(branch_1, 192, (7, 1), name='inceptionb_bn_1c')\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'Incpetion_Block-C':\n","        branch_0 = Conv2d_bn(x, 192, (1, 1), name='inceptionc_bn_0')\n","        branch_1 = Conv2d_bn(x, 192, (1, 1), name='inceptionc_bn_1a')\n","        branch_1 = Conv2d_bn(branch_1, 192, (1, 3), name='inceptionc_bn_1b')\n","        branch_1 = Conv2d_bn(branch_1, 192, (3, 1), name='inceptionc_bn_1c')\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: ' + str(block_type))\n","    mixed = Concatenate(axis=3)(branches)\n","    \n","    '''確保輸入跟輸出深度相同'''\n","    up = Conv2d_bn(mixed,K.int_shape(x)[3],1,activation=None)\n","    \n","    '''導入殘差結構，並給予權重'''\n","    \n","    x = Lambda(lambda inputs, scale: inputs[0]+ inputs[1] * scale, ##提示inputs[0]、inputs[1]\n","               output_shape=K.int_shape(x)[1:],\n","               arguments={'scale': scale},)([x,up])\n","    \n","    if activation is not None:\n","        x = Activation(activation)(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDFRa5s-5b35","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"8fc449db-d7d6-40a3-d3be-0e7b01a8cebf","executionInfo":{"status":"ok","timestamp":1580952834300,"user_tz":-480,"elapsed":1929,"user":{"displayName":"Jian-Jhih Lai","photoUrl":"","userId":"06705720842516758594"}}},"source":["# 定義人臉關鍵點檢測網路\n","img_input = Input(shape=imgs_train.shape)\n","x=inception_resnet_block(img_input, 0.1, 'Incpetion_Block-A', activation='relu')\n","x=inception_resnet_block(x, 0.1, 'Incpetion_Block-B', activation='relu')\n","x=inception_resnet_block(x, 0.1, 'Incpetion_Block-C', activation='relu')\n","\n","# 定義神經網路的輸入, hidden layer 以及輸出\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(output_dim=30,activation='softmax')(x)\n","\n","inputs = img_input\n","model = Model(inputs=img_input, name='inception_resnet', outputs=predictions)\n","\n","# 配置 loss funtion 和 optimizer\n","model.compile(loss='mean_squared_error', optimizer='sgd')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=30)`\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kH8yBjyf5b39","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}